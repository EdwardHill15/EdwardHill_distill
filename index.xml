<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ted Laderas, PhD on Ted Laderas, PhD</title>
    <link>/</link>
    <description>Recent content in Ted Laderas, PhD on Ted Laderas, PhD</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Reframing Impostor Syndrome as the Road to Mastery</title>
      <link>/2018/12/13/reframing-impostor-syndrome-as-being-on-the-road-to-mastery/</link>
      <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/13/reframing-impostor-syndrome-as-being-on-the-road-to-mastery/</guid>
      <description>

&lt;p&gt;At some point in your life in Data Science, you will probably struggle with &lt;a href=&#34;https://www.apa.org/gradpsych/2013/11/fraud.aspx&#34; target=&#34;_blank&#34;&gt;impostor syndrome&lt;/a&gt;. We all do - in fact, even though I have used R and have done bioinformatics and data science for more than 15 years, I still struggle with this feeling. As a beginner, the mountain you must climb to master skills in data science seems like a long and impossible one.&lt;/p&gt;

&lt;p&gt;Caitlin Hudon, in her post about &lt;a href=&#34;https://caitlinhudon.com/2018/01/19/imposter-syndrome-in-data-science/&#34; target=&#34;_blank&#34;&gt;dealing with impostor syndrome&lt;/a&gt; has this to say about countering impostor syndrome:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The way that I’ve dealt with imposter syndrome is this: I’ve accepted that I will never be able to learn everything there is to know in data science — I will never know every algorithm, every technology, every cool package, or even every language — and that’s okay. The great thing about being in such a diverse field is that nobody will know all of these things (and that’s okay too!).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I think it&amp;rsquo;s important to try and reframe the feelings of impostor syndrome into something more positive. I think having self-compassion about the difficulties of the learning process can help.&lt;/p&gt;

&lt;p&gt;George Leonard&amp;rsquo;s &lt;a href=&#34;https://www.goodreads.com/book/show/81940.Mastery&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Mastery&lt;/em&gt;&lt;/a&gt; is a short book that I think can help provide the antidote to these feelings of fraud and inadequacy. I feel that beginners and learners would feel much better if their instructors would own up to their own personal shortcomings as learners. That is, instead of trying to project the image of the all knowledgable guru, instructors should show themselves as humble, lifelong learners as well.&lt;/p&gt;

&lt;p&gt;In &lt;a href=&#34;https://www.goodreads.com/book/show/81940.Mastery&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Mastery&lt;/em&gt;&lt;/a&gt;, Leonard talks about our unrealistic expectations and how these expectations can get in the way of actually learning and mastering a craft. We are conditioned by ads, movies, and social media that mastering a craft is a never ending set of ever rising climaxes (cue the &lt;a href=&#34;https://www.youtube.com/watch?v=SPFCHuEegsk&#34; target=&#34;_blank&#34;&gt;training montage&lt;/a&gt;), that we can make continuous and steady progress by working hard enough.&lt;/p&gt;

&lt;p&gt;Mastering a craft takes practice, and lots of it. We must learn to be contented to practice when we are on a plateau and are not making visible progress. As Leonard notes,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The Path to Mastery is practice.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Leonard outlines 5 principles that can sustain us in our road to mastery and away from impostor syndrome: &lt;strong&gt;Instruction&lt;/strong&gt;, &lt;strong&gt;Practice&lt;/strong&gt;, &lt;strong&gt;Surrender&lt;/strong&gt;, &lt;strong&gt;Intentionality&lt;/strong&gt;, and &lt;strong&gt;The Edge&lt;/strong&gt;. I&amp;rsquo;m trying to map common feelings of impostor syndrome and show how these principles can counteract these feelings.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Instruction&lt;/strong&gt;. Leonard emphasizes the importance in finding good instructors and good mentorship that will help us to grow. Finding good instructors can actually be difficult and finding someone who remembers what it was like to be learning something is important. Avoid those instructors who say things like &amp;ldquo;it should now be obvious&amp;rdquo; or are disparaging when you don&amp;rsquo;t understand something.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;He or she is not necessarily the one that gives the most polished lectures, but rather the &lt;em&gt;one who has discovered how to involve each student actively&lt;/em&gt; in the process of learning.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;What you can do today&lt;/em&gt;: look at twitter and other forums for your community of learners and support those who give good instruction. Realize that not all teachers are good teachers; leave them and seek better ones if necessary.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Practice&lt;/strong&gt;. Practice for practices&amp;rsquo; sake. Deliberate practice where you slowly build up your understanding and perceptions is important to your growth.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Where in our upbringing, our schooling, our career are we taught to value, to enjoy, even to love the plateau, the long stretch of diligent effort with no seeming progress?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;What you can do today&lt;/em&gt;: Join communities of practice such as Tidy Tuesday and share your learning with others. Tidy Tuesday is extremely friendly and encouraging for beginners. Learn together and grow together. These are safe communities to share knowledge.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Intentionality&lt;/strong&gt;. This goes hand in hand with practice. Deliberate practice requires visualizing your process and guiding yourself gently.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Intentionality fuels the master&amp;rsquo;s journey. Every master is a master of vision.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;What you can do today&lt;/em&gt;: find small exercises and projects that help you reinforce what you&amp;rsquo;ve learned so far. Find people&amp;rsquo;s code and vignettes and modify them until you understand what they&amp;rsquo;ve done and how they structured their work.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Surrender&lt;/strong&gt;. At some point, you will have to give up your own social position as an expert to grow as a learner. When this happens, you must be willing to risk that standing to progress further. Leonard talks about a karate master learning aikido who was not willing to start from scratch, which impeded his learning. For many of us academics, being willing to abandon the comfort of what we have learned is especially difficult. We feel like we are risking our own social standing and reputation.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;For the master, surrender means there are no experts. There are only Learners.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;What you can do today&lt;/em&gt;: be humble when faced with new concepts (for many impostor syndrome sufferers this is not the hard part). Recognize when you need to grow and when you have to leave old concepts behind.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Edge&lt;/strong&gt;. This is where things are undefined and scary. Still, part of the journey to mastery is a willingness to push your thoughts to beyond the horizon of what you thought was possible.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The trick here is not only to test the edges of the envelope, but also to walk the fine line between endless, goalless practice and those alluring roles that appear along the way.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;What you can do today&lt;/em&gt;: Identify some goals that are just beyond your current skillset and be willing to push your learning to that point.&lt;/p&gt;

&lt;p&gt;Leonard maintains that true mastery is not due to innate talent. True mastery is due to tenacity and perserverance in the face of difficult learning. In fact, he suggests that learning things too easily means that you might lack perserverance when the going gets rough and your progress slows. He maintains that someone who perseveres will &amp;ldquo;have learned whatever [they] are practicing to the marrow of [their] bones.&amp;rdquo;&lt;/p&gt;

&lt;h2 id=&#34;encouraging-mastery-as-a-community&#34;&gt;Encouraging Mastery as a Community&lt;/h2&gt;

&lt;p&gt;I think Caitlin&amp;rsquo;s &lt;a href=&#34;https://caitlinhudon.com/2018/01/19/imposter-syndrome-in-data-science/&#34; target=&#34;_blank&#34;&gt;prescriptions for community wide suggestions for reducing impostor syndrome&lt;/a&gt; are wonderful. Especially the advice to &amp;ldquo;Get comfortable with I don&amp;rsquo;t know&amp;rdquo;. Normalizing &amp;ldquo;I don&amp;rsquo;t know&amp;rdquo; within a community is incredibly important to making a psychologically safe learning environment.&lt;/p&gt;

&lt;p&gt;To encourage learners, I think that creating a community of practice and helpfulness is vitally important to give new learners the support they need. When communities take responsibility for the learning of their members, something magic happens. Learning no longer feels lonely and there is no shame when you don&amp;rsquo;t immediately grasp a concept. Patience becomes the norm and people become more confident.&lt;/p&gt;

&lt;p&gt;For me, this is the true value of schools and universities. To get the most out of online learning, you need to participate within a community that encourages you to learn further. Be on the pathway to mastery by participate within learning communities.&lt;/p&gt;

&lt;h2 id=&#34;further-reading&#34;&gt;Further Reading&lt;/h2&gt;

&lt;p&gt;Mastery: &lt;a href=&#34;https://www.goodreads.com/book/show/81940.Mastery&#34; target=&#34;_blank&#34;&gt;https://www.goodreads.com/book/show/81940.Mastery&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Things we learned teaching clinical data wrangling</title>
      <link>/2018/10/15/clinical-data-wrangling/</link>
      <pubDate>Mon, 15 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/15/clinical-data-wrangling/</guid>
      <description>&lt;p&gt;Well, we just finished our &lt;a href=&#34;https://laderast.github.io/clinical_data_wrangling/&#34;&gt;clinical data wrangling workshop&lt;/a&gt;. This was a 12 hour workshop (spread over 4 days) where students got to work with a real research dataset (the &lt;a href=&#34;http://sleepdata.org&#34;&gt;Sleep Heart Health Study&lt;/a&gt; data). This is a workshop that we developed as part of an National Library of Medicine T15 training supplement in Data Science. The following is a short report describing the workshop and its outcomes.&lt;/p&gt;
&lt;div id=&#34;intended-audience&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Intended Audience&lt;/h2&gt;
&lt;p&gt;We designed the workshop for our incoming informatics students (both clinical and biological majors) in order to introduce them to the difficulties of working with clinical data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;learning-objectives&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Learning Objectives&lt;/h2&gt;
&lt;p&gt;These were our learning objectives for the workshop:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Understand the biology of sleep and sleep apnea and how the biology informs the covariates measured in the Sleep Heart Health Study&lt;/li&gt;
&lt;li&gt;Understand why clinical data is useful and also why it’s difficult to work with&lt;/li&gt;
&lt;li&gt;Learn Exploratory Data Analysis techniques and use them to inform model building.&lt;/li&gt;
&lt;li&gt;Learn to assess logistic regression models using simple diagnostics.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;the-dataset&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Dataset&lt;/h2&gt;
&lt;p&gt;We used the &lt;a href=&#34;https://sleepdata.org/datasets/shhs&#34;&gt;Sleep Heart Health Study&lt;/a&gt; dataset from the &lt;a href=&#34;https://sleepdata.org&#34;&gt;National Sleep Research Resource&lt;/a&gt;. This is a dataset of approximately 5800 patients that have over 3000 covariates. We limited our students to a smaller number of covariates (17), including our outcome of interest, cardiovascular disease.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;workshop-format&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Workshop Format&lt;/h2&gt;
&lt;p&gt;We designed the workshop to be a mix of didactic lectures and active learning exercises. Where possible, we had students work in groups to answer questions about the data. These activities included a data scavenger hunt using our EDA exploration app, and a logistic modeling exercise.&lt;/p&gt;
&lt;div id=&#34;day-1-outline&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Day 1 Outline&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Introduction, logistics, and groups assigned (30 minutes)&lt;/li&gt;
&lt;li&gt;Biology of Sleep and Cardiovascular Disease (40 minutes, format: in-person lecture)&lt;/li&gt;
&lt;li&gt;Break Time (15 minutes)&lt;/li&gt;
&lt;li&gt;The Value of Clinical Data (15 minutes, in-person lecture)&lt;/li&gt;
&lt;li&gt;Clinical Data Quality (40 minutes, in-person lecture)&lt;/li&gt;
&lt;li&gt;Lunch (90 minutes, with optional R setup session)&lt;/li&gt;
&lt;li&gt;Exploring the SHHS Dataset (60 minutes, format: Data Scavenger Hunt w/ Shiny App, each team gets a task and has to show the class how to find the information)&lt;/li&gt;
&lt;li&gt;Applying the Clinical Wrangling Process: Diabetes (45 minutes, format: in-person lecture)&lt;/li&gt;
&lt;li&gt;Logistic Regression Model Basics (60 minutes, format: walkthrough of R Notebook)&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;day-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Day 2&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Question/Answer session about Logistic Regression and Modeling (50 minutes)&lt;/li&gt;
&lt;li&gt;Assignment about &lt;code&gt;race&lt;/code&gt; variable (assigned to groups, take-home assignment)&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;day-3&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Day 3&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Discussion about &lt;code&gt;race&lt;/code&gt; as a covariate, sharing of findings&lt;/li&gt;
&lt;li&gt;Overview of hypertension and how it relates to cardiovascular disease and sleep apnea&lt;/li&gt;
&lt;li&gt;Template/R Notebook given for final presentation in groups (in-class lab time, template is structured as a series of decisions.)&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;day-4&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Day 4&lt;/h3&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Group presentations about covariate decisions and resulting model (1 hour, present final version of R notebook). At each decision stage, teams must decide on whether or not to include covariates or not given what they have found from exploring the data and justify their decision using EDA visualizations.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;lessons-learned&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Lessons Learned&lt;/h2&gt;
&lt;p&gt;Overall, we believe the workshop went well, as it encouraged discussion about data and its appropriateness among the students. Students were engaged overall and asked lots of questions.&lt;/p&gt;
&lt;p&gt;The final reports for each group were generated from a R Notebook. All three groups showed a thoughtful narrative and justification for each of the covariates included in the model.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Interactive visualization removes barriers to understanding issues in data&lt;/strong&gt;. Ted developed a Shiny App that allowed the students to visually browse and understand the data. Along with the EDA scavenger hunt (see below), this served as a good introduction for students to get their feet wet with the SHHS dataset.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Our diverse backgrounds helped make the workshop accessible.&lt;/strong&gt; Nicole Weiskopf has a background in data quality of clinical data, Eilis Boudreau does sleep study work, and I’m a bit of a mongrel.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Securing the cooperation of the data holders made the workshop possible&lt;/strong&gt;. The dataset comes from the National Sleep Study Resource. Eilis knows Susan Redline, who heads that group and pitched the idea (over two sessions) to her group. Susan’s group was very enthusiastic and helpful, especially in helping the students get their data use agreements in so they could access the dataset.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Group work is learning work&lt;/strong&gt;. We assigned each student to a group, and gave each group questions to answer and teach the class about the dataset. By pointing them to specific aspects of the data, we opened the door to discussion.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;EDA scavenger hunt&lt;/strong&gt;. We had the students learn data exploration by giving them a scavenger hunt to look at the relationship between variables. Each group was then required to talk about their findings and which visualization helped them discover that relationship. For example, there is a relationship between age and race in our dataset; the “Other” category of race has a lower median age than the other two categories, “White” and “Black”.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Didactic Teaching is also important&lt;/strong&gt;. Nicole and Eilis covered both the biology of sleep apnea and the difficulty of understanding the implications of clinical data. Without this background, students would not be able to make informed decisions about their final model.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Guide the Students, but don’t force discussion&lt;/strong&gt;. This was important. We think the students need to connect the dots to really understand the issues. The final product (a logistic regression model predicting cardiovascular disease with an R Notebook) had steps and choices. But the choices for each group of students was different.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;A Code of conduct is necessary and important&lt;/strong&gt;. We are big believers in psychological safety. If people don’t feel safe in the classroom environment (and let’s face it, grad school classrooms rarely are), they will be less likely to learn and contribute.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data restrictions made deploying difficult&lt;/strong&gt;. The activity materials were deployed as an RStudio project. However, we couldn’t share the data within a GitHub repo. As OHSU’s approved vendor is Box, we setup a box folder containing the material to be shared with students.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We were grateful for the incoming informatics students’ enthusiasm and patience as we got this workshop going. Also thanks to the NLM T15 Supplement in Data Science, without which we would not have gotten the opportunity to conceptualize, put together, and deliver this workshop. Thanks again to Susan Redline and the &lt;a href=&#34;http://sleepdata.org&#34;&gt;National Sleep Research Resource&lt;/a&gt; group, especially Dan Mobley who helped us with the last-minute data use agreements.&lt;/p&gt;
&lt;p&gt;Link to Workshop: &lt;a href=&#34;https://github.com/laderast/clinical_data_wrangling&#34; class=&#34;uri&#34;&gt;https://github.com/laderast/clinical_data_wrangling&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Turning down the noise</title>
      <link>/2018/08/02/turning-down-the-noise/</link>
      <pubDate>Thu, 02 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/02/turning-down-the-noise/</guid>
      <description>

&lt;p&gt;I&amp;rsquo;m still in the process of recovering from my current bout of depression and anxiety. I&amp;rsquo;d like to talk about what is currently helping me moderate my anxiety. I have been practicing mindfulness and meditation for the past three years and I&amp;rsquo;m beginning to realize how necessary it is in our information dense age. Many of my symptoms of anxiety are really from an information overglut.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m currently on way too many projects and am teaching as well. Everything wants my attention. We need to decide dates for a visit, etc. Booking travel, grading students, etc. The noise of academic life can be overwhelming and can prevent me from working effectively. A book I&amp;rsquo;m reading, &lt;em&gt;Real Happiness at Work&lt;/em&gt; by Sharon Salzberg, talks about Attention Deficit Trait disorder:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Attention deficit trait (ADT) is workplace-induced attention deficit caused by the constant, relentless input of information, these days usually enabled by our high-tech devices, smartphones, and computers.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is especially prevalent for people like me who are on multiple grants and have many collaborators. I&amp;rsquo;m okay with putting out the occasional fire or dealing with an emergency deadline; if I believe in the project, I can muster the energy. However, the problem is when I have multiple fires to deal with from multiple people. The task switching leads to stress and leads to an inability to prioritize. This is where I&amp;rsquo;ve been the last few months.&lt;/p&gt;

&lt;p&gt;And this is when the voices of doubt begin to fuel my anxiety. On top of the enormous task list, there&amp;rsquo;s the feelings of failure and disappointment because I can&amp;rsquo;t get simple things done. In my head the voices reach a frenzy, a cacophony, a noise. And then I can&amp;rsquo;t think straight, prioritize, work on one thing.&lt;/p&gt;

&lt;p&gt;What is the solution to ADT and the noise of life? Mindfulness and unitasking. As Sharon Salzberg notes:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;hellip; while it’s unrealistic to try to stop the number and variety of incoming demands, in our technologically advanced world it is possible to modulate how much information we’re taking in, and how many tasks we are doing at once. When we slow down and concentrate on doing just what is before us to be done now, &lt;strong&gt;we become the masters of our own environment rather than its frantic slaves.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This idea (being a master of my environment) appeals to me in the midst of my academic anxiety. Practicing mindfulness (through daily meditation) helps me to focus on the here and now. We are wired to ruminated about the past (things we wish we&amp;rsquo;d done better) or the future (oh crap, I need to prepare upcoming stuff). Meditation is all about building that focus and attention on what&amp;rsquo;s before us. If we can&amp;rsquo;t do it all, we can at least work on what&amp;rsquo;s right in front of us.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve also been reading Anne Lamott&amp;rsquo;s &lt;em&gt;Bird by Bird&lt;/em&gt;, a book reflecting on the hows and whys of writing and living your life while doing it. It&amp;rsquo;s a sobering view of why we write and how to keep on in the face of numerous adversities. There&amp;rsquo;s one passage that really resonated with me in the chapter called &amp;ldquo;Shitty First Drafts&amp;rdquo; in dealing with the incessant chatter of life:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Close your eyes and get quiet for a minute, until the chatter starts up. Then isolate one of the voices and imagine the person speaking as a mouse. Pick it up by the tail and drop it into a mason jar. Then isolate another voice, pick it up by the tail, drop it in the jar. And so on. Drop any high maintenance parental units, drop in any contractors, lawyers, colleagues, children, anyone else who is whining in your head. Then put the lid on, and watch all these mouse people clawing at the glass, jabbering away, trying to make you feel like shit because you won&amp;rsquo;t do what they want - won&amp;rsquo;t give them more money, won&amp;rsquo;t be more successful, won&amp;rsquo;t see them more often. Then imagine there is a volume control button on the bottle. Turn it all the way up for a minute, and listen to the stream of angry, neglected, guilt-mongering voices. Then turn it all the way down and watch the frantic mice lunge at the glass, trying to get to you. Leave it down, and get back to your shitty first draft.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is another idea in mindfulness: &lt;em&gt;welcoming and acknowledging our worries and negative voices&lt;/em&gt;. If we ignore or refuse these feelings, they just become stronger and louder in the din and the noise. I have all sorts of these feelings: &lt;em&gt;I don&amp;rsquo;t work hard enough&lt;/em&gt;, &lt;em&gt;I&amp;rsquo;m a failure&lt;/em&gt;, &lt;em&gt;I&amp;rsquo;m letting down people who depend on me&lt;/em&gt;, &lt;em&gt;Everyone is out there working on cooler things than me&lt;/em&gt;. Now I&amp;rsquo;m trying to take an effort to welcome these feelings into my mental space, saying &amp;ldquo;okay, I hear you and acknowledge you, so you don&amp;rsquo;t have to be yelling anymore&amp;rdquo;. And surprisingly, they do quiet down. Acknowledging the feelings of failure, thanking them for their contribution to the discussion and showing them the door is important. As Kelly Boys says in &lt;em&gt;The Blind Spot Effect&lt;/em&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you approach life with a willingness to be with what you encounter without getting lost in it, it moves gracefully within your experience.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And that helps lower the volume and free your attention.&lt;/p&gt;

&lt;p&gt;If you are feeling generalized anxiety or attention deficit trait, I encourage you to look into mindfulness as a way of turning down the noise.&lt;/p&gt;

&lt;h2 id=&#34;resources&#34;&gt;Resources&lt;/h2&gt;

&lt;p&gt;These are some of the resources that I&amp;rsquo;ve used when writing this post.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/gp/product/0692475389/&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;The Mindful Geek: Secular Meditation for Smart Skeptics&lt;/em&gt;&lt;/a&gt; by Michael Taft. This is a great book for people who are interested in Mindfulness and the psychological and neuroscience research about why mindfulness works in reducing depression and anxiety. I started here. Michael Taft calls meditation &amp;ldquo;a technology for hacking the human wetware to improve your life&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/Real-Happiness-Work-Meditations-Accomplishment/dp/B0182Q7KAQ/&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Real Happiness at Work: Meditations for Accomplishment, Achievement, and Peace&lt;/em&gt;&lt;/a&gt; by Sharon Salzberg. This is a nice followup to &lt;em&gt;Mindful Geek&lt;/em&gt;, talking about how we can regain control in our workplace.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/Blind-Spot-Effect-Missing-Whats-ebook/dp/B07413Q5Y7/&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;The Blind Spot Effect: How to Stop Missing What&amp;rsquo;s Right in Front of You&lt;/em&gt;&lt;/a&gt; by Kelly Boys. I am really liking this book so far. It&amp;rsquo;s about how meditation and mindfulness can help us find our cognitive blind spots and move beyond them.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/Bird-Some-Instructions-Writing-Life/dp/0385480016/&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Bird by Bird: Some Instructions on Writing and Life&lt;/em&gt;&lt;/a&gt; by Anne Lamott. I recently started reading this on vacation. Writing can be a lonely and solitary life, and I find many of her suggestions about living to apply equally well to research.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A gRadual Introduction to Shiny</title>
      <link>/2018/01/24/gradual-introduction-to-shiny/</link>
      <pubDate>Wed, 24 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/24/gradual-introduction-to-shiny/</guid>
      <description>&lt;p&gt;I just gave a workshop teaching the basics of &lt;a href=&#34;https://shiny.rstudio.com&#34; target=&#34;_blank&#34;&gt;Shiny&lt;/a&gt; (the interactive web visualization framework) for a group of PDX R users. We had 10 people attend, and most of the attendees managed to get through the material and had lots of good questions. I really enjoyed talking with everyone and I hope everyone learned something. We&amp;rsquo;re planning to give the workshop again to the larger PDX R user community, and some of the attendees last night have volunteered to be TAs.&lt;/p&gt;

&lt;p&gt;The workshop materials consist of a &lt;a href=&#34;https://github.com/laderast/shiny_workshop_pdxrlang&#34; target=&#34;_blank&#34;&gt;GitHub repo&lt;/a&gt; and a &lt;a href=&#34;https://laderast.github.io/shiny_workshop_pdxrlang/&#34; target=&#34;_blank&#34;&gt;Markdown document&lt;/a&gt; that can be done either in person or independently. The materials are freely available under an Apache 2.0 License.&lt;/p&gt;

&lt;p&gt;In the workshop, we build a flexible &lt;code&gt;csv&lt;/code&gt; (comma separated value) explorer that can load in &lt;code&gt;csv&lt;/code&gt; data files with adaptive controls and tooltips.&lt;/p&gt;

&lt;p&gt;In terms of packages, the workshop uses the &lt;code&gt;tidyverse&lt;/code&gt; (mostly &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;ggplot2&lt;/code&gt;), and &lt;code&gt;plotly&lt;/code&gt; to show some basic programming patterns in &lt;code&gt;shiny&lt;/code&gt;:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Connecting controls to &lt;code&gt;ggplot2&lt;/code&gt; aesthetics&lt;/li&gt;
&lt;li&gt;Filtering data using &lt;code&gt;reactive&lt;/code&gt;s&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;observe&lt;/code&gt;/&lt;code&gt;update_&lt;/code&gt; pattern&lt;/li&gt;
&lt;li&gt;Tooltips (the hard way/the plotly way)&lt;/li&gt;
&lt;li&gt;The final product&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I&amp;rsquo;d love for more people to take a look at the workshop and would &lt;a href=&#34;https://github.com/laderast/shiny_workshop_pdxrlang/issues/2&#34; target=&#34;_blank&#34;&gt;love any suggestions&lt;/a&gt; for making it better!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What We learned teaching Python to Neuroscience Students</title>
      <link>/2018/01/17/what-we-learned-teaching-python-to-neuroscience-students/</link>
      <pubDate>Wed, 17 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/17/what-we-learned-teaching-python-to-neuroscience-students/</guid>
      <description>

&lt;p&gt;Well, the week of teaching our &lt;a href=&#34;https://github.com/dasaderi/python_neurobootcamp&#34; target=&#34;_blank&#34;&gt;Python Bootcamp for Neuroscientists&lt;/a&gt; is over. I had the pleasure of working with a great group of students, professors and instructors in developing the material, and had a great time teaching complete beginners to programming and Python.&lt;/p&gt;

&lt;p&gt;We had the overall goal of introducting 21 &lt;a href=&#34;http://www.ohsu.edu/xd/education/schools/school-of-medicine/academic-programs/neuroscience-graduate-program/&#34; target=&#34;_blank&#34;&gt;Neuroscience Graduate Program&lt;/a&gt; students at OHSU to the basics of programming in Python using data that they were interested in: electrophysiology data, and confocal microscopy data. The course was designed to be a 1 credit course to encourage students to persist and finish it.&lt;/p&gt;

&lt;p&gt;The format of the class was spread over 5 days (2.5 hours a day) and had the following schedule:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Introduction to basic data types in Python&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Introduction to for loops and Pandas DataFrames&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Using Pandas to analyse electrophysiology data&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Using NumPy to analyse confocal microscopy data&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Evaluation of students; installing Python/Juypter; wrap-up with questions.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I&amp;rsquo;ll just write up some random thoughts about our experiences about the course. We are definitely planning to give the course again next year, given the enthusiastic reception.&lt;/p&gt;

&lt;h3 id=&#34;things-that-really-worked-well&#34;&gt;Things that really worked well&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Avoid the first day blues of installing Python by using &lt;a href=&#34;https://github.com/jupyterhub/jupyterhub&#34; target=&#34;_blank&#34;&gt;JupyterHub&lt;/a&gt;&lt;/strong&gt;. I think one of the major pain points for beginners is installing software before they can even learn. Instead of making them install Python the first day, we had them sign into an AWS server that had JuypterHub deployed. &lt;a href=&#34;https://github.com/jupyterhub/jupyterhub&#34; target=&#34;_blank&#34;&gt;JupyterHub is a multi-user server for Juypter Notebooks&lt;/a&gt; which had the right version of Python and our need the dependencies installed. So our students just needed a laptop and a web browser to access our lessons. We could update the notebooks by pulling changes from our course repo.&lt;/p&gt;

&lt;p&gt;Stephen David, my fellow instructor, figured a lot of the difficult deployment details out. He has put together some &lt;a href=&#34;https://github.com/dasaderi/python_neurobootcamp/blob/master/server_setup/hubInstall.md&#34; target=&#34;_blank&#34;&gt;handy instructions about deploying JuypterHub to AWS&lt;/a&gt; and keeping the accounts updated via a GitHub repo in case other people are interested in using our bootcamp materials.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Make the atmosphere welcoming to beginners&lt;/strong&gt;. In order to do so, we used many great tips from Software/Data Carpentry: modeling resilience by using live coding (and making mistakes along the way), using post-it notes for students to signal when they need help or are finished, and having plenty of TAs per student (at least 4 students/TA or instructor). We tried to emphasize that learning programming is an ongoing process, and that even we still have to Google errors on Stack Overflow. Showing that you can make mistakes and still recover is a big part of that.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Plan some early wins and make the exercises as interactive as possible.&lt;/strong&gt; For the most part, we tried to avoid lecturing too long and break up the session with interactive exercises. I also really don&amp;rsquo;t like workshops where the trainer/teacher moves on no matter whether people understand the material or not. By using the post-its to signal when they were done, we were able to more appropriately pace the workshop. We also planned on stopping points if we couldn&amp;rsquo;t get through the day&amp;rsquo;s materials.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Emphasize working together and building a community.&lt;/strong&gt; From the beginning, we emphasized that everyone needed to work together. I always emphasize the chain of help: 1) First your programming partner, 2) then the TA help. Discussing and working on issues together fosters a sense of community. I think there will be a group of students who will really want to learn more because of this.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Getting feedback along the way&lt;/strong&gt;. I still feel like being a teacher is about 75% preparation and 25% improvisation. You need to be flexible enough to come up with examples on the fly, and you need to evaluate whether students are getting the material along the way. The exercises we tried to sprinkle throughout the notebooks helped us understand where people were stumbling.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Planning follow-up sessions&lt;/strong&gt;. Through BioData Club, we&amp;rsquo;re planning some follow-up sessions. Through DataCamp in the Classroom, I also got our students premium access. We also pointed students out to &lt;a href=&#34;/python_resources/&#34;&gt;other Python-based courses at OHSU&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;some-things-we-could-improve-on&#34;&gt;Some things we could improve on&lt;/h3&gt;

&lt;p&gt;I believe that given our time frame, we couldn&amp;rsquo;t really have anticipated many of these issues. We did our best to deal with them in the moment, however.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Describing the difference between Jupyter Notebooks and Python&lt;/strong&gt;. At the beginning, we glossed over what a Jupyter Notebook was and really didn&amp;rsquo;t describe its relation to Python. I think next time we will open with describing the relationship between Jupyter and Python with a diagram, and revisit it on the last day.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Anticipate the JupyterHub server requirements better&lt;/strong&gt;. On Day 3, we had a large dataset that basically hosed the server because 21 students were trying to open it up at once. We managed to recover by getting another AWS server and dividing the students among the two, but we could have stress tested that day a little more. Lesson learned.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Going slowly enough&lt;/strong&gt;. I am a very excitable teacher, to the point of which sometimes I go a little too fast. I have to confess that I may have sped through some of the material a little too fast. As a result, some of the students didn&amp;rsquo;t quite get what functions like &lt;code&gt;enumerate()&lt;/code&gt; were for and the concept of &lt;em&gt;unpacking&lt;/em&gt; a list. Luckily, Brad Buran covered these on Day 4 and the students felt comfortable enough to finish the programming test on the final day.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Setting student expectations&lt;/strong&gt;. It&amp;rsquo;s vital to show the students that they can learn programming, but also what&amp;rsquo;s possible if they do. One of the days was a big leap from the previous day, but we did mention that it&amp;rsquo;s really to show them what&amp;rsquo;s possible if they continued to learn about programming.&lt;/p&gt;

&lt;h3 id=&#34;would-we-do-it-again&#34;&gt;Would we do it again?&lt;/h3&gt;

&lt;p&gt;I would definitely say yes! We had to waitlist some students who really wanted to take it, and our overall feedback about the course was really positive. I hope that we can have more TAs, and have the future data workshops be more student driven.&lt;/p&gt;

&lt;h3 id=&#34;acknowlegements&#34;&gt;Acknowlegements&lt;/h3&gt;

&lt;p&gt;This was a collaboration between the Neuroscience Graduate Program (NGP) and the Department of Medical Informatics and Clinical Epidemiology (DMICE).&lt;/p&gt;

&lt;p&gt;The NGP students involved in designing and testing the material were&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Daniela Sadieri&lt;/li&gt;
&lt;li&gt;Lucille Moore&lt;/li&gt;
&lt;li&gt;Charles Heller&lt;/li&gt;
&lt;li&gt;Zack Schwartz&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Faculty/Instructors involved were:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Brad Buran  (Research Instructor)&lt;/li&gt;
&lt;li&gt;Stephen David (NGP Assistant Professor)&lt;/li&gt;
&lt;li&gt;Lisa Karstens (DMICE Assistant Professor)&lt;/li&gt;
&lt;li&gt;Michael Mooney (DMICE Assistant Professor)&lt;/li&gt;
&lt;li&gt;Ted Laderas (DMICE Assistant Professor)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thanks very much to Gary Westbrook (Director of the NGP program), Shannon McWeeney (Head of the Division of Bioinformatics and Computational Biology within DMICE), and Bill Hersh (Head of DMICE).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>If you want to talk with me for an informational interview</title>
      <link>/2018/01/15/if-you-want-to-talk-with-me-for-an-informational-interview/</link>
      <pubDate>Mon, 15 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/15/if-you-want-to-talk-with-me-for-an-informational-interview/</guid>
      <description>&lt;p&gt;I have had many people who have asked me for informational interviews. They tell me that they are interested in Data Science and want to hear about what I do on a day to day basis. To be honest, I&amp;rsquo;ve begun to dread these kinds of interviews.&lt;/p&gt;

&lt;p&gt;Inevitably, I spend a &lt;em&gt;lot&lt;/em&gt; of energy explaining what I do to someone who rarely follows up. Consequently, I don&amp;rsquo;t find these interviews rewarding at all. So I&amp;rsquo;ve written this post so that I have a better time doing these kinds of interviews.&lt;/p&gt;

&lt;p&gt;I reserve the right to refuse interviews from people who do not read this.&lt;/p&gt;

&lt;p&gt;1) &lt;em&gt;Do your homework&lt;/em&gt;. Please don&amp;rsquo;t expect me to give the five minute spiel about my research, hoping to look for an &amp;ldquo;in&amp;rdquo;. Please do some research and try to ask &lt;em&gt;interesting&lt;/em&gt; questions about my work. I&amp;rsquo;ve given you plenty of resources on this website to know more about me. Ask me about my software, ask me about teaching, ask me carefully thought questions about my research.&lt;/p&gt;

&lt;p&gt;2) &lt;em&gt;Don&amp;rsquo;t offer to buy me coffee&lt;/em&gt;. If I talk with you for 30 minutes, know that my time is worth far more than a cup of coffee. Instead, offer to pay it forwards. Volunteer with a group that does scientific communication or education; I don&amp;rsquo;t work with people who aren&amp;rsquo;t willing to teach others. I don&amp;rsquo;t work or talk with selfish people, having been burned many times by such people.&lt;/p&gt;

&lt;p&gt;3) &lt;em&gt;Be specific in your ask&lt;/em&gt;. Asking about what next steps to take in learning data science and where to get a job is not specific enough. Again, do your research. What kinds of Data Science are you interested in? Are you interested in predictive analytics in healthcare? Or are you interested in systems modeling of disease? Be specific, and if you ask for something, make sure I can &lt;a href=&#34;https://www.samuelthomasdavies.com/the-five-minute-favour/&#34; target=&#34;_blank&#34;&gt;achieve it in five minutes or less&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;4) &lt;em&gt;Don&amp;rsquo;t ask for a job, ask for connections&lt;/em&gt;. I know a decent number of people around Oregon and OHSU, so if you want me to introduce you to one of my connections, I&amp;rsquo;m happy to. If I know someone, I&amp;rsquo;m happy to do this, since it&amp;rsquo;s usually a five-minute ask.&lt;/p&gt;

&lt;p&gt;5) &lt;em&gt;Follow up, and be willing to return the favor&lt;/em&gt;. Even a nice thank-you email is good. I&amp;rsquo;m happy to make you a Linkedin connection, if it means I can help someone else further down the line. If I expend energy on you, I&amp;rsquo;d like to see my impact. If my efforts meant that you managed to find a job, please let me know!&lt;/p&gt;

&lt;p&gt;6) &lt;em&gt;Read &lt;a href=&#34;http://www.adamgrant.net&#34; target=&#34;_blank&#34;&gt;Give and Take&lt;/a&gt;&lt;/em&gt;. This book by Adam Grant really struck me as the way to actually network. In short, I learned that if I want a return on my energy expenditure, I have to spend my energy on Givers, or people who help others. I am a Giver, but I now tend only to give informational interviewers to other Givers. The rest are too draining for me.&lt;/p&gt;

&lt;p&gt;I have given so many of these interviews and have gotten nothing from them. Not even a follow-up, which really is bad practice. So, if I&amp;rsquo;m considered difficult to approach about these, know it is because your previous askers have really been an energy drain and have been inconsiderate Takers. Make it interesting for me and be considerate. I&amp;rsquo;m much more likely to help you.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Python_resources</title>
      <link>/python_resources/</link>
      <pubDate>Fri, 12 Jan 2018 13:55:55 -0800</pubDate>
      
      <guid>/python_resources/</guid>
      <description>

&lt;p&gt;A list of python resources at OHSU and beyond for the neuroscience students.&lt;/p&gt;

&lt;h2 id=&#34;in-neuroscience&#34;&gt;In Neuroscience&lt;/h2&gt;

&lt;h3 id=&#34;python-bootcamp-for-neuroscientists-neus640&#34;&gt;Python Bootcamp for Neuroscientists (NEUS640)&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dasaderi/python_neurobootcamp&#34; target=&#34;_blank&#34;&gt;Course Material&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This course is a gentle introduction to the Python
programming language using data types familiar to Neuroscience students, including behavioral, electrophysiology, and imaging data. Emphasis will be put on introducing students to concepts of visualization, data manipulation, and analysis using available Python packages (NumPy, Pandas, Matplotlib).&lt;/p&gt;

&lt;h2 id=&#34;in-medical-informatics-and-clinical-epidemiology-dmice&#34;&gt;In Medical Informatics and Clinical Epidemiology (DMICE)&lt;/h2&gt;

&lt;h3 id=&#34;introduction-to-programming-no-course-number&#34;&gt;Introduction to Programming (no course number)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Instructor: Lisa Karstens, Ph.D.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;0.0 credits&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ohsu.edu/xd/education/schools/school-of-medicine/departments/clinical-departments/dmice/current-students/student-resources/upload/IntroductionToProgramming-Syllabus-WI18.pdf&#34; target=&#34;_blank&#34;&gt;Course Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Offered: Winter and Summer Quarter&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This non-credit, online course will introduce the beginning programmer to programming structure and design, creating a solid foundation for all types of programming. The emphasis will be on procedural programming and control structures, although exercises will be in Python. The course fulfills the prerequisite for BMI 540 and BMI 565. Tuition fee is $500.&lt;/p&gt;

&lt;p&gt;Students may register during the regular winter and summer term registration periods. Contact Diane Doctor for details at doctord@ohsu.edu.&lt;/p&gt;

&lt;h3 id=&#34;bioinformatics-programming-and-scripting-bmi-565-656&#34;&gt;Bioinformatics Programming and Scripting - BMI 565 / 656&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Instructor: Michael Mooney, Ph.D.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Credits: 3.0&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ohsu.edu/xd/education/schools/school-of-medicine/departments/clinical-departments/dmice/current-students/student-resources/upload/BMI-565-Syllabus-FA17.pdf&#34; target=&#34;_blank&#34;&gt;Syllabus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Offered: Fall Quarter&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The purpose of this course is to equip research scientists with computational skills necessary to create and automate tools to analyze biological data.  The course is divided into four sub-topics: python programming, scripting in unix, biopython library, bioinformatics workflows.  Python will be used used to solve simple to sophisticated programming problems and to review general computational language paradigms such as problem abstraction, data types, file I/O, iteration, functions, and objects.  There will also be an emphasis on writing unix operating system shell scripts to automate repetitive tasks and connect disparate bioinformatics tools using files and pipes.  In addition, students will learn to access public repositories to perform basic bioinformatics tasks such as annotating gene products, sequence searching, and functional queries. This course is designed to be a first year requirement for students in the Bioinformatics and Computational Biology graduate program in Biomedical Informatics. Open to other students with consent of instructor.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Prerequisite&lt;/strong&gt;: Background must include an introductory programming class including concepts such as variables, loops, I/O, methods, and algorithms.&lt;/p&gt;

&lt;h2 id=&#34;computer-science-and-electrical-engineering-cs-ee-python-courses&#34;&gt;Computer Science and Electrical Engineering (CS/EE) Python Courses&lt;/h2&gt;

&lt;h3 id=&#34;data-science-programming-cs-527-627&#34;&gt;Data Science Programming - CS 527 / 627&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://cslu.ohsu.edu/~kain/CS627/&#34; target=&#34;_blank&#34;&gt;Course Website&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This course is designed to give you awareness and initial working knowledge of some of the most fundamental computational tools for performing a wide variety of academic research. As such, it will focus on providing breadth instead of depth, which means that for each concept we will talk about motivation, key concepts, and concrete usage scenarios, but without mathematical background or proofs, which can be acquired in more specialized classes. In this class we will: become familiar with the UNIX/LINUX environment, learn how to version control files with git, write programs inpython, perform numeric tasks using numpy and scipy, analyze data using pandas, apply machine learning algorithms using scikit-learn, visualize data using matplotlib and pyqtgraph, use QT/pyside to build graphical user interfaces, and finally we will address performance issues via compilation/profiling/parallelization tools.&lt;/p&gt;

&lt;h3 id=&#34;introduction-to-image-processing-ee-584-684&#34;&gt;Introduction to Image Processing EE 584 / 684&lt;/h3&gt;

&lt;p&gt;This course covers basic image processing principles and techniques with a brief introduction to machine vision. Specific topics include image transform methods, image filtering, image enhancement, image restoration, segmentation, image representation and feature extraction, image recognition and classification, and image compression. Application of these techniques is illustrated in numerous examples. Pre-requisite: probability and statistics or equivalent, calculus, linear algebra and proficiency in at least one high-level programming language.&lt;/p&gt;

&lt;h3 id=&#34;data-visualization-cs-631&#34;&gt;Data Visualization CS 631&lt;/h3&gt;

&lt;p&gt;This course will give students a foundation in the principles of data visualization, particularly as applied to scientific and technical data, as well as provide students with hands-on experience using modern software tools for developing visualizations. Lecture topics will include an overview of visual perception, color theory and practice, different types of graphs and their purposes, visualizations for specialized forms of data including time-series and geospatial data sets, strategies for working with multidimensional data, etc. There will also be lecture content on ethical issues surrounding data visualization. Weekly lab sessions will introduce students to popular data visualization tools such as R&amp;rsquo;s ggplot and Shiny, Tableau, etc.&lt;/p&gt;

&lt;h2 id=&#34;datacamp&#34;&gt;DataCamp&lt;/h2&gt;

&lt;p&gt;NEUS640 Students will have access to DataCamp for the next 6 months.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>So You&#39;ve Accidentally Checked in a Large File Into Git</title>
      <link>/2018/01/05/so-you-ve-accidentally-checked-in-a-large-file-into-git/</link>
      <pubDate>Fri, 05 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/05/so-you-ve-accidentally-checked-in-a-large-file-into-git/</guid>
      <description>&lt;p&gt;&lt;em&gt;Note: after posting this, I heard back from Roberto Tyley, the creator of the BFG. I&amp;rsquo;d like to note that the BFG actually does its job really well. I was mostly really frustrated about how Git/GitHub doesn&amp;rsquo;t prevent a user from doing something that&amp;rsquo;s hard to undo. So my frustration is really about that, not really about the BFG. This post has been edited to reflect that.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Greg Wilson first said it, but I&amp;rsquo;ve come to agree. Git is an aggressively antisocial piece of software. Git is a piece of software that can make developers with any amount of experience feel dumb.&lt;/p&gt;

&lt;p&gt;Recently, I accidentally checked a large file (greater than 100 Megs) into my local repo. When I tried to push to GitHub, of course, it refused it (I know about git large file storage, but I don&amp;rsquo;t have any).&lt;/p&gt;

&lt;p&gt;So my local repo was screwed up. Of course, I did what seemed like the rational thing and deleted the file from my repo and recommitted. More than once. This is a mistake I&amp;rsquo;ve done more than once. So you need to scrub your git history with BFG so that GitHub will accept your lowly commits again.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://rtyley.github.io/bfg-repo-cleaner/&#34; target=&#34;_blank&#34;&gt;The BFG&lt;/a&gt; documentation specifies how to fix a &lt;em&gt;remote&lt;/em&gt; repo. I would say that this situation is much less common than the local situation. So I just decided to share how I got the BFG to work for the local repo situation.&lt;/p&gt;

&lt;p&gt;I usually install the BFG through &lt;code&gt;homebrew&lt;/code&gt;, using &lt;code&gt;brew install bfg&lt;/code&gt;. When you install it this way, you can just run BFG with &lt;code&gt;bfg&lt;/code&gt;. You can download it from the website, but you&amp;rsquo;ll have to call &lt;code&gt;java -jar bfg[VERSION].jar&lt;/code&gt; to run it.&lt;/p&gt;

&lt;p&gt;Say you&amp;rsquo;ve accidently checked in a large file into your current repo. The first thing to do is to clone your local repo:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone --mirror local_repo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will create another folder called &lt;code&gt;local_repo.git&lt;/code&gt; that you will do all the BFG magic on. This &lt;code&gt;local_rep.git&lt;/code&gt; is what is called a &lt;em&gt;bare&lt;/em&gt; repo. I want to remove any files larger than 100 Megs, so I do this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bfg -b 100M local_repo.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If this doesn&amp;rsquo;t return an error, you can move on. However, I got the dreaded error:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Warning : no large blobs matching criteria found in packfiles - 
does the repo need to be packed?
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Augh. Ok, some googling later I found that I needed to pack my orignal repo:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd local_repo
git repack
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Okay, we need to get rid of our cloned repo and redo the last few steps.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;rm -rf local_repo.git
git clone --mirror local_repo
bfg -b 100M local_repo.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then comes some git commands that no one has bothered to explain to me.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git reflog expire --expire=now --all &amp;amp;&amp;amp; git gc --prune=now --aggressive
git push
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Uh oh, I get a &lt;code&gt;remote: error: refusing to update checked out branch: refs/heads/master&lt;/code&gt; error! More ugh.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s the trick. Since you cloned a &lt;em&gt;local&lt;/em&gt; repo, you need to set the origin of your current repo (&lt;code&gt;local_repo.git&lt;/code&gt;) to the GitHub remote. First we remove the current &lt;code&gt;origin&lt;/code&gt;, and then add back our remote.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git remote rm origin
git remote add origin https://github.com/laderast/remote_repo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, after much gnashing of the teeth, we can&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git push
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Don&amp;rsquo;t forget to remove your now &lt;em&gt;dirty&lt;/em&gt; &lt;code&gt;local_repo&lt;/code&gt;, and the mirrored copy, and then pull a fresh copy down!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;##remove both original local repo and altered bare repo
rm -rf local_repo
rm -rf local_repo.git
##clone a fresh copy from GitHub
git clone https://github.com/laderast/remote_repo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This may be obvious to the 10 people in the world who have read all of the git documentation, but I am not one of them. I&amp;rsquo;m stuck with git, unfortunately. I&amp;rsquo;m writing this post to remind me of what to do when I innocently do something like commit a large file to my repo.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Understanding Tidy Evaluation in R</title>
      <link>/2017/12/19/understanding-tidyeval/</link>
      <pubDate>Tue, 19 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/12/19/understanding-tidyeval/</guid>
      <description>&lt;p&gt;Have you ever had something that no matter how many times someone explained it, you really had no idea what it was for? For me, that was Non Standard Evaluation (NSE) in R, and its newer cousin Tidy Evaluation, or &lt;code&gt;tidyeval&lt;/code&gt;. I had a real learning block about it. I really wanted to understand it, but for some reason I just really wasn’t getting the general concepts.&lt;/p&gt;
&lt;p&gt;What is evaluation, really? For the longest time, I was extremely confused about it. When you provide an expression to R such as:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(rlang)
this_variable &amp;lt;- 2
this_variable * 6&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You notice that there is an output to &lt;code&gt;this_variable * 6&lt;/code&gt;, which is &lt;code&gt;12&lt;/code&gt;. Evaluation is really about looking up variable names in an environment and then acting on the results. What is going on here is that R looks for an object that is named &lt;code&gt;this_variable&lt;/code&gt; in our global environment, and then returns the value, &lt;code&gt;2&lt;/code&gt;, which it then &lt;em&gt;substitutes&lt;/em&gt; in the expression. So our original expression:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;this_variable * 6&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Becomes this expression:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;2 * 6&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Which R knows how to calculate, the output of which is &lt;code&gt;12&lt;/code&gt;. But sometimes you want to pass an expression or a variable, as is, without evaluating it first. The best case for this is to passing a variable into a function. We can do this by wrapping them up in &lt;code&gt;quosures&lt;/code&gt; or &lt;code&gt;enquosures&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;A &lt;code&gt;quosure&lt;/code&gt; and an &lt;code&gt;enquosure&lt;/code&gt; can be thought of as envelopes around an object. They obscure certain properties of the object until they can be delivered into a function. The envelopes basically are a way to sneak variables and expressions into a function’s environment. When the envelope is in the function, we can open it up and evaluate what’s in the envelope. The trick to NSE and tidyeval is that we can control when the function &lt;em&gt;evaluates&lt;/em&gt; the expression, by controlling when we open this envelope. We do this by using the &lt;code&gt;UQ()&lt;/code&gt; or &lt;code&gt;!!&lt;/code&gt; functions.&lt;/p&gt;
&lt;p&gt;In other words, &lt;code&gt;quosures&lt;/code&gt; and &lt;code&gt;enquosures&lt;/code&gt; are ways to prevent R from looking up a variable’s value in our current environment (usually the global environment), and delay this lookup until we get them into the environment of interest. This might be one level down (in our function of interest), or several levels down (in a function called by our function).&lt;/p&gt;
&lt;p&gt;The point is, R won’t open the envelope with our variable in it until we tell it to.&lt;/p&gt;
&lt;div id=&#34;why-should-i-care&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Why Should I Care????&lt;/h2&gt;
&lt;p&gt;The short answer: if you want to write functions that directly work with the &lt;code&gt;tidyverse&lt;/code&gt;, you need to understand &lt;code&gt;tidyeval&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The best way to understand why you need to do this is to write a function that takes a &lt;code&gt;data.frame&lt;/code&gt; and a reference to a column within that &lt;code&gt;data.frame&lt;/code&gt;. You might notice that we can directly refer to a column in a &lt;code&gt;data.frame&lt;/code&gt; for &lt;code&gt;select&lt;/code&gt;, for example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mtcars %&amp;gt;% select(cyl) %&amp;gt;% head(10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                   cyl
## Mazda RX4           6
## Mazda RX4 Wag       6
## Datsun 710          4
## Hornet 4 Drive      6
## Hornet Sportabout   8
## Valiant             6
## Duster 360          8
## Merc 240D           4
## Merc 230            4
## Merc 280            6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Why does that work? This is the power of NSE and tidy evaluation. Basically, by wrapping up &lt;code&gt;cyl&lt;/code&gt; in an envelope, we prevent R from &lt;em&gt;evaluating&lt;/em&gt; it right away. We can then pass the envelope into other functions, or environments, and then tell R to remove the envelope and then &lt;em&gt;evaluate&lt;/em&gt; it.&lt;/p&gt;
&lt;p&gt;Let’s try and mimic this. We’ll write a function &lt;code&gt;grab_col(x, colname)&lt;/code&gt; which returns the values in the column whose name we ask for as an object. If we do this, without tidyeval, this will happen.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grab_col &amp;lt;- function(x, colname){
  x %&amp;gt;%
    pull(colname)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Try running &lt;code&gt;grab_col(mtcars, colname=cyl)&lt;/code&gt;. You’ll get an error that &lt;code&gt;cyl&lt;/code&gt; does not exist as an object. Augh! This is harder than we thought.&lt;/p&gt;
&lt;p&gt;How can we fix this? We can wrap &lt;code&gt;colname&lt;/code&gt; up in an &lt;code&gt;enquosure&lt;/code&gt; using the &lt;code&gt;enquo()&lt;/code&gt; function. Once it’s into &lt;code&gt;pull()&lt;/code&gt;, we use &lt;code&gt;UQ()&lt;/code&gt; to open the envelope and R knows that it should look in the &lt;code&gt;data.frame&lt;/code&gt;’s environment for our &lt;code&gt;colname&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rlang)

grab_col &amp;lt;- function(x, colname){
  ##wrap up colname in an enquosure
  cc &amp;lt;- rlang::enquo(colname)

  ##use UQ to evaluate it within the pull function
  x %&amp;gt;%
    pull(
      ## unquote and evaluate (open the envelope!)
      UQ(cc)
      )
}

grab_col(mtcars, colname=cyl)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now try &lt;code&gt;grab_col(mtcars, colname=cyl)&lt;/code&gt;. Nifty, huh?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;with-quosures-values-can-come-along-for-the-ride&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;With &lt;code&gt;quosure&lt;/code&gt;s, values can come along for the ride&lt;/h2&gt;
&lt;p&gt;Why would we use &lt;code&gt;quosure&lt;/code&gt;s at all, instead of &lt;code&gt;enquosure&lt;/code&gt;s? Because with &lt;code&gt;quosure&lt;/code&gt;s we can actually bring some needed values along for the ride.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-about-lots-of-arguments&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What about lots of arguments?&lt;/h2&gt;
&lt;p&gt;That’s what &lt;code&gt;quos()&lt;/code&gt; is for. Ever notice that you can specify a number of unnamed arguments by specifying a &lt;code&gt;...&lt;/code&gt; in your function definition? And did you ever notice that &lt;code&gt;select()&lt;/code&gt; can take lots of arguments such as &lt;code&gt;select(mpg, cyl, wt)&lt;/code&gt;? That is the power of &lt;code&gt;...&lt;/code&gt; combined with &lt;code&gt;quos()&lt;/code&gt;!&lt;/p&gt;
&lt;p&gt;&lt;code&gt;quos&lt;/code&gt; takes a list and makes each element of the list a &lt;code&gt;quosure&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-about-expressions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What about expressions?&lt;/h2&gt;
&lt;p&gt;Say we wanted to pass an expression such as &lt;code&gt;cyl &amp;gt; 2&lt;/code&gt; into our function. We’ll need to wrap it up in &lt;code&gt;enexpr()&lt;/code&gt; instead of &lt;code&gt;enquo()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter_on_column &amp;lt;- function(x, col_expr){
  c_e &amp;lt;- rlang::enexpr(col_expr)

  x %&amp;gt;%
    ## The !! (called a bangbang) is just another way to use UQ()
    ## I don&amp;#39;t really like it, I&amp;#39;d rather use UQ()
    filter(!! c_e)
}

#pass in a simple expression
mtcars %&amp;gt;% filter_on_column(cyl &amp;gt; 2) %&amp;gt;% head(5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    mpg cyl disp  hp drat    wt  qsec vs am gear carb
## 1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
## 2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
## 3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
## 4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
## 5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#pass in a compound expression
mtcars %&amp;gt;% filter_on_column(cyl &amp;gt; 2 &amp;amp; qsec &amp;gt; 18) %&amp;gt;% head(5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    mpg cyl  disp  hp drat    wt  qsec vs am gear carb
## 1 22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1
## 2 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1
## 3 18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1
## 4 24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2
## 5 22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;be-really-careful-with&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Be really careful with &lt;code&gt;!!&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;In the above example, we used &lt;code&gt;!!&lt;/code&gt;, called a bangbang, to unquote and evaluate our expression. Be really careful with what you put after the &lt;code&gt;!!&lt;/code&gt;, since everything after it will be evaluated. If you have elements after the expression you don’t want to unquote, wrap the &lt;code&gt;!!&lt;/code&gt; up in a set of parentheses:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bang &amp;lt;- function(val2){
  x &amp;lt;- enquo(val2)
  return((!! x) + 10)
}

bang(5)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;other-applications&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Other applications&lt;/h2&gt;
&lt;p&gt;One of the coolest applications of NSE is to write code that writes code. You have to be very careful with this, but it’s potentially really useful. On my list of things to do for my &lt;code&gt;flowDashboard&lt;/code&gt; package is to write code that generates a standalone app given the data objects you supply it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix-what-is-a-quosure-really&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Appendix: What is a &lt;code&gt;quosure&lt;/code&gt;, really?&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;for-more-information&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;For more information&lt;/h2&gt;
&lt;p&gt;Hopefully this was helpful in understanding NSE and tidyeval. I find that sometimes I have to write things up so I more clearly understand it. So, if anything, writing this was useful for clarifying my thinking.&lt;/p&gt;
&lt;p&gt;I’m indebted to Edwin Thoen’s code examples that helped me finally understand what’s going on with &lt;code&gt;tidyeval&lt;/code&gt;: &lt;a href=&#34;https://edwinth.github.io/blog/dplyr-recipes/&#34; class=&#34;uri&#34;&gt;https://edwinth.github.io/blog/dplyr-recipes/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I didn’t really talk about Base-R’s NSE, but I would say that this should at least give you enough background to understand what’s going on there.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Using Synthetic Data for Teaching Data Science</title>
      <link>/2017/12/14/using-synthetic-data/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/12/14/using-synthetic-data/</guid>
      <description>&lt;p&gt;Hi Everyone, our paper called &lt;a href=&#34;https://www.biorxiv.org/content/early/2017/12/12/232611&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Teaching data science fundamentals through realistic synthetic clinical cardiovascular data&lt;/em&gt;&lt;/a&gt; is now available to read on Biorxiv.&lt;/p&gt;

&lt;p&gt;In this paper, we talk about a dataset that we synthesized for teaching aspects of clinical data that may be tricky to understand in data science. This dataset is interesting because it&amp;rsquo;s derived from a multivariate distribution based on real patient data, modeled as a Bayesian Network. Even when we knew true marginals for the real data, there was a lot of fine tuning to the Bayesian Network.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ve used this dataset for a couple of classes, and we&amp;rsquo;ve found that it helps highlight real issues in predictive modeling of clinical data. One of the largest is that most predictive models are based on a much older patient cohort (50+), which means that we don&amp;rsquo;t know much about how to predict cardiovascular risk in younger patients. Part of the teaching exercise is having the students choose a cohort of interest and then attempt to predict on that patient cohort.&lt;/p&gt;

&lt;p&gt;The data is currently available as an R package here, including vignettes about how the data was generated: &lt;a href=&#34;https://github.com/laderast/cvdRiskData&#34; target=&#34;_blank&#34;&gt;https://github.com/laderast/cvdRiskData&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Notes on Open Data Science Conference West 2017</title>
      <link>/2017/11/07/odsc-notes/</link>
      <pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/07/odsc-notes/</guid>
      <description>

&lt;p&gt;I just came back from the &lt;a href=&#34;https://odscwest.pathable.com&#34; target=&#34;_blank&#34;&gt;Open Data Science Conference&lt;/a&gt; (ODSC) in San Francisco and I found it really stimulating and interesting. I learned a ton, met some great people working in very different fields, and overall found it quite worthwhile.&lt;/p&gt;

&lt;p&gt;Here are some of the highlights from my notes:&lt;/p&gt;

&lt;h2 id=&#34;workshops&#34;&gt;Workshops&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/amueller/ml-training-intro&#34; target=&#34;_blank&#34;&gt;scikit-learn intro Workshop&lt;/a&gt; and &lt;a href=&#34;https://github.com/amueller/ml-training-advanced&#34; target=&#34;_blank&#34;&gt;Advanced&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I admit that I am not really a Python person. But I am helping to develop some materials for an introductory workshop and I found this workshop and its materials to be a very beginner-friendly to &lt;code&gt;scikit-learn&lt;/code&gt; and machine learning concepts, much like &lt;code&gt;caret&lt;/code&gt; for R. All the slides and workshop materials are available at the above links.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/WinVector/ODSCWest2017&#34; target=&#34;_blank&#34;&gt;SparklyR Workshop&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I liked this workshop from John Mount of Win-Vector. It started out with a &lt;em&gt;dplyr&lt;/em&gt; intro, and introduced us to the basics of Apache Spark, which is a cluster-computing based machine learning framework, which is designed to do very large queries and machine learning. RStudio&amp;rsquo;s Edgar Ruiz managed to get us each an RStudio Pro Instance running on AWS with all the required packages installed so we could test out the SparklyR package, which uses dplyr&amp;rsquo;s commands to run Spark jobs.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://drive.google.com/file/d/0B3MFD2S4MhtGd1ltVHZkbFhHX0ZUbGlGZmtNRjllQ2NtQkJN/view?usp=sharing&#34; target=&#34;_blank&#34;&gt;In-Memory Computing Essentials for Data Scientists&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This was an introduction to Apache Ignite, which is a distributed, in-memory database that can be leveraged by different languages. The really interesting thing about Ignite is that it will colocate related data on the same cluster node, resulting in rapid queries within each node. I think this technology will become very important as we need more datasets to be openly accessible to compute on.&lt;/p&gt;

&lt;h2 id=&#34;talks&#34;&gt;Talks&lt;/h2&gt;

&lt;p&gt;These were the most interesting talks that I attended.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://mfviz.com/odsc-2017/#/&#34; target=&#34;_blank&#34;&gt;Visually Explaining Statistical and Machine Learning Concepts&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This was a great talk by Mike Freedman about his process of how he put together D3.js based visualizations to explain some statistical concepts. I thought the explanation of his process (isolate specific ideas, identify data structures, leverage visualization algorithms). Check out the slides above. They&amp;rsquo;re very cool.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://odscwest.pathable.com/meetings/596522&#34; target=&#34;_blank&#34;&gt;The Wonder Twins: Data Science and Human Centered Design&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This was a really interesting talk about the interplay between data science and design in helping encourage a mobile money system in Tanzania. It was inspiring to see how they had both designers and data scientists embedded and looking at how the mobile payment system worked. One interesting example was doing network analysis of the Mobile Money Agents, who distribute cash. They targeted a highly influential group of these agents based on this analysis. Very cool.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://odscwest.pathable.com/meetings/601861&#34; target=&#34;_blank&#34;&gt;The People&amp;rsquo;s Data&lt;/a&gt;
and &lt;a href=&#34;https://odscwest.pathable.com/meetings/604496&#34; target=&#34;_blank&#34;&gt;The Deontology of Data Science&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I thought these were really interesting sides about the human side of data science. DJ Patil, who was chief data scientist under the Obama administration, talked about citizen-driven data projects and how it enabled a number of advances. The most interesting case was basically a parent built an online community of people who had a very rare disease condition so he could help his son with the condition.&lt;/p&gt;

&lt;p&gt;Igor Perisic (of LinkedIn) followed this with a talk about ethical issues in data science. In particular, he identified three different areas to concentrate on: 1) The Ethics of Data, 2) The Ethics of Algorithms, and 3) The Ethics of practice. He concentrated on the recent New York Times article about using &lt;a href=&#34;https://www.nytimes.com/2017/05/01/us/politics/sent-to-prison-by-a-software-programs-secret-algorithms.html&#34; target=&#34;_blank&#34;&gt;machine learning to identify potential re-offenders in the prison system&lt;/a&gt;. The lack of transparency in how the algorithm identifies potential reoffenders is a huge ethical problem.&lt;/p&gt;

&lt;p&gt;In all, I had an interesting time and I met lots of people in industry, which was a nice contrast to the academic side of things.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On the Separation of Code and State</title>
      <link>/2017/08/22/separation-of-code-and-state/</link>
      <pubDate>Tue, 22 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/08/22/separation-of-code-and-state/</guid>
      <description>&lt;p&gt;One of the hardest concepts as an analyst that I have struggled with is separating my code from my data. A related issue is making your code reproducible across data instances.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Interesting useR 2017 Talks</title>
      <link>/2017/07/05/interesting-user2017talks/</link>
      <pubDate>Wed, 05 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/07/05/interesting-user2017talks/</guid>
      <description>&lt;p&gt;Since I didn&amp;rsquo;t get to go to useR 2017 this year, I&amp;rsquo;m compiling the interesting talks. This is an ongoing list.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://user2017.sched.com/event/AxqM/automatically-archiving-reproducible-studies-with-docker&#34; target=&#34;_blank&#34;&gt;https://user2017.sched.com/event/AxqM/automatically-archiving-reproducible-studies-with-docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://user2017.sched.com/event/Axq4/clouds-containers-and-r-towards-a-global-hub-for-reproducible-and-collaborative-data-science&#34; target=&#34;_blank&#34;&gt;https://user2017.sched.com/event/Axq4/clouds-containers-and-r-towards-a-global-hub-for-reproducible-and-collaborative-data-science&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://user2017.sched.com/event/Axq9/scraping-data-with-rvest-and-purrr&#34; target=&#34;_blank&#34;&gt;https://user2017.sched.com/event/Axq9/scraping-data-with-rvest-and-purrr&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://user2017.sched.com/event/Axq1/using-the-alphabetr-package-to-determine-paired-t-cell-receptor-sequences&#34; target=&#34;_blank&#34;&gt;https://user2017.sched.com/event/Axq1/using-the-alphabetr-package-to-determine-paired-t-cell-receptor-sequences&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://user2017.sched.com/event/AxqG/show-me-the-errors-you-didnt-look-for&#34; target=&#34;_blank&#34;&gt;https://user2017.sched.com/event/AxqG/show-me-the-errors-you-didnt-look-for&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://user2017.sched.com/event/AxqR/community-based-learning-and-knowledge-sharing&#34; target=&#34;_blank&#34;&gt;https://user2017.sched.com/event/AxqR/community-based-learning-and-knowledge-sharing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://user2017.sched.com/event/AxqT/r-based-computing-with-big-data-on-disk&#34; target=&#34;_blank&#34;&gt;https://user2017.sched.com/event/AxqT/r-based-computing-with-big-data-on-disk&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://user2017.sched.com/event/AxqA/codebookr-codebooks-in-r&#34; target=&#34;_blank&#34;&gt;https://user2017.sched.com/event/AxqA/codebookr-codebooks-in-r&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://user2017.sched.com/event/Axor/how-we-built-a-shiny-app-for-700-users&#34; target=&#34;_blank&#34;&gt;https://user2017.sched.com/event/Axor/how-we-built-a-shiny-app-for-700-users&lt;/a&gt; Useful concepts: reactiveTrigger to force a rerender.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://user2017.sched.com/event/AxsL/ensemble-packages-with-user-friendly-interface-an-added-value-for-the-r-community&#34; target=&#34;_blank&#34;&gt;https://user2017.sched.com/event/AxsL/ensemble-packages-with-user-friendly-interface-an-added-value-for-the-r-community&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>How to Not Be Afraid of Your Data</title>
      <link>/2017/06/28/howtonotbeafraid/</link>
      <pubDate>Wed, 28 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/06/28/howtonotbeafraid/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m going to be giving a talk for the PDX RLang Meetup on July 11 called &amp;ldquo;&lt;a href=&#34;https://www.meetup.com/portland-r-user-group/events/240846589/&#34; target=&#34;_blank&#34;&gt;How to Not Be Afraid of Your Data: Teaching EDA using Shiny&lt;/a&gt;&amp;rdquo;. Abstract below.&lt;/p&gt;

&lt;p&gt;Many graduate students in the basic sciences are afraid of data exploration and cleaning, which can greatly impact their downstream analysis results. By using a synthetic dataset, some simple &lt;code&gt;dplyr&lt;/code&gt; commands, and a &lt;code&gt;shiny&lt;/code&gt; dashboard, we teach graduate students how to explore their data and how to handle issues that can arise (missing values, differences in units). For this talk, we&amp;rsquo;ll run through a simple EDA example (combining two weight loss datasets) with a general data explorer in &lt;code&gt;shiny&lt;/code&gt; that can be easily customized to teach specific EDA concepts.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Some Lessons We Learned Running Cascadia-R</title>
      <link>/2017/06/07/cascadiarnotes/</link>
      <pubDate>Wed, 07 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/06/07/cascadiarnotes/</guid>
      <description>&lt;p&gt;Well, the first &lt;a href=&#34;http://cascadiarconf.com&#34; target=&#34;_blank&#34;&gt;Cascadia R Conference&lt;/a&gt; has come and gone. I have to say that it was super fun, and well attended (over 190 people!). I had a blast meeting and chatting with everyone. Hopefully, we showed newbies that R is learnable and others that there are lots more things to learn about R.&lt;/p&gt;

&lt;p&gt;The following is my attempt to document what we learned from organizing Cascadia-R. It&amp;rsquo;s not complete; I may add and subtract from it as I think of more things to say about the planning process.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Decide the tone&lt;/strong&gt;. Our goals with Cascadia-R were modest. We wanted to get a diverse group of R users together in a safe and encouraging environment. We wanted our workshops to be accessible to even beginners, and encourage them in the use of R.&lt;/p&gt;

&lt;p&gt;Part of meeting these goals of this is setting the tone. We really wanted to encourage all levels of R users to attend. All of our flyers, emails and promotional tweets encouraged beginners to come. We got help with making a &lt;a href=&#34;https://cascadiarconf.com/coc/&#34; target=&#34;_blank&#34;&gt;Code of Conduct&lt;/a&gt; for the conference. Part of creating a supportive environment is encouraging diversity in both speakers and attendees. We did our best to reach out to current groups that encourage diversity, such as &lt;a href=&#34;http://wisportland.weebly.com&#34; target=&#34;_blank&#34;&gt;Women in Science Portland&lt;/a&gt;, and &lt;a href=&#34;https://rladies.org&#34; target=&#34;_blank&#34;&gt;R-Ladies Global&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We also offered diversity scholarships to encourage people from diverse backgrounds to attend, and made diversity part of our criteria for selecting talks.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Start planning early&lt;/strong&gt;. As junior faculty at OHSU, I&amp;rsquo;m lucky enough to be able to book facilities here, including the large learning studios where we held the conference. Having the venue secured early on made the remaining logistics of the conference much easier.&lt;/p&gt;

&lt;p&gt;Much like wedding planning, there are plenty of conference planning services out there who would be happy to take over aspects of your conference, for a fee. You can spend however much you want to on these things. However, I believe that such a approach is not financially responsible. I also feel that taking a more DIY/bespoke approach can make a conference most engaging (see &lt;a href=&#34;https://csvconf.com&#34; target=&#34;_blank&#34;&gt;csvconf&lt;/a&gt;). We tried to do most things ourselves (including design, promotion, talk submission, workshops, and registration/logistics).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Iterate your budget&lt;/strong&gt;. Think of a conference as a project with lots of linked dependencies. Your first plan is probably not going to be your final plan. Start a plan, iterate, realize that things are going to shift, have a backup plan. What if registration is not going to pay for the venue rental fee? Talking to simpatico sponsors can take much of the financial stress. In our case, the &lt;a href=&#34;https://www.rstudio.com&#34; target=&#34;_blank&#34;&gt;Rstudio&lt;/a&gt; foundation and &lt;a href=&#34;https://ropensci.org&#34; target=&#34;_blank&#34;&gt;ROpenSci&lt;/a&gt; stepped up to contribute some money as a cushion.&lt;/p&gt;

&lt;p&gt;Remember, there are &lt;em&gt;fixed costs&lt;/em&gt; (such as venue rental, and recording/streaming costs) and &lt;em&gt;variable costs&lt;/em&gt; that scale with the number of attendees (food, badges, alcohol). Separate these out. When possible, pay off the fixed costs first, so that it&amp;rsquo;s easier to manage the variable costs.&lt;/p&gt;

&lt;p&gt;Again, who is your desired audience and can they afford your conference? We decided to make our conference as affordable as possible to encourage as many different kinds of people to attend. We initially wanted to make attendance free for students. The problem with free is that literally it&amp;rsquo;s free. It has no value in the mind of a person who accepts free admission. So we decided to charge students a small fee just to emphasize that the conference has value.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Talk with others who have done it&lt;/strong&gt;. We were very clueless about much of the logistics side at OHSU. I managed to get through by talking with a number of people here (including Robin Champieux and Shannon McWeeney) who have done conferences here at OHSU. Thank you so much for your invaluable advice.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Encourage each other and delegate&lt;/strong&gt;. No one of us could have done all of the conference planning alone. Each of us took on various aspects of conference organization and brought in the others as support as needed. Some of us selected talks, some of us did design, and we all pitched in to get registration working as efficiently and quickly as possible.&lt;/p&gt;

&lt;p&gt;Our slack channel on &lt;a href=&#34;https://pdxdata.slack.com&#34; target=&#34;_blank&#34;&gt;pdxdata.slack.com&lt;/a&gt; is full of our decisions. Slack was so useful as a planning mechanism that we only met online via Google Hangouts a few times, and only had two in-person planning sessions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Be Willing to Make Mistakes&lt;/strong&gt;. Lord knows I made a bunch of mistakes when I made announcements and hosted the lightning sessions. However, I owned up to these mistakes, shrugged, and moved on. Improvising in the moment can be just as important as planning.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Think about the future&lt;/strong&gt;. What should the next Cascadia-R look like? I know it just happened, but we&amp;rsquo;re trying to envision what it would look like. Based on the feedback we&amp;rsquo;ve gotten so far, people really want more workshops!&lt;/p&gt;

&lt;p&gt;In a following post, I&amp;rsquo;m also going to talk about lessons I learned when Chester and I put on our tidyverse workshop.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
